{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Métricas de Equidade em Aprendizado de Máquina e seus Fundamentos Éticos e Políticos\n",
        "author: Fernando Pasquini Santos - Department of Computer Science, Calvin University\n",
        "format:\n",
        "    revealjs:\n",
        "        selfcontained: false\n",
        "        width: 1200\n",
        "        slide-number: true\n",
        "        max-scale: 2\n",
        "        slide-level: 2\n",
        "        scrollable: true\n",
        "execute:\n",
        "  echo: true\n",
        "include-in-header:\n",
        "  - text: |\n",
        "      <style>\n",
        "      #title-slide .title {\n",
        "        font-size: 2em;;\n",
        "      }\n",
        "      .small-text {\n",
        "      font-size: 0.7em; /* Adjust the value to your desired text size */\n",
        "      }\n",
        "      </style>\n",
        "---\n",
        "\n",
        "\n",
        "## Sociedade da competição\n",
        "\n",
        "Pressuposto: um mundo de recursos limitados e, portanto, de competição em todos os lugares e todas as áreas.\n",
        "\n",
        "- em empregos/admissões\n",
        "- em provas/testes/avaliações\n",
        "- em honras/medalhas/etc\n",
        "- em dinheiro/crédito\n",
        "\n",
        "*\"O mundo é feito de ganhadores e perdedores\"*\n",
        "\n",
        "- Justiça, então, seria garantir que a competição é justa (\"fair game\")\n",
        "\n",
        "## Inequidade e discriminação\n",
        "\n",
        "Três possíveis sentidos:\n",
        "\n",
        "1. Atribuir vantagem/desvantagem a alguém com base em **critérios errados de relevância**\n",
        "2. Atribuir vantagem/desvantagem a alguém com base em **estereótipos e generalizações**\n",
        "3. Atribuir vantagem/desvantagem a alguém com base em **coisas sobre as quais a pessoa não tem controle**\n",
        "\n",
        "## Automação e burocracia\n",
        "\n",
        "Por que buscamos?\n",
        "\n",
        "1. Automação permite escalar o sistema\n",
        "2. Regras e procedimentos formais, *em teoria*, reduzem a arbitrariedade e tornam o raciocínio explícito.\n",
        "    - Supõem de que o processo apenas envolve conhecimento explícito (e não tácito)\n",
        "\n",
        "## Automação e burocracia\n",
        "\n",
        "No caso do uso de Machine Learning: \"decisão baseada em dados\"\n",
        "\n",
        "  - Parece algo formal, mas o raciocínio acaba sendo uma caixa-preta (opacidade epistêmica)\n",
        "  - Dados introduzem problemas:\n",
        "    - Arbitrariedade na anotação dos dados (*target labeling*)\n",
        "    - Arbitrariedade na seleção dos atributos/*features*\n",
        "    - Limite da indução\n",
        "  - Taxa de erros: maior ou menor?\n",
        "  - Responsabilização e possibilidade de recursos?\n",
        "\n",
        "## Nosso exemplo: conjunto de dados ficcional {.smaller}\n",
        "\n",
        "- 1.000 linhas, onde cada linha representa o perfil de um estudante, com atributos relacionados ao desempenho acadêmico e não acadêmico, necessidade financeira e informações demográficas.\n",
        "- Informações são geralmente consideradas em decisões sobre concessão de bolsas de estudo.\n",
        "\n",
        "1. **`Student_ID`**: um identificador único para cada estudante.\n",
        "2. **`GPA`**: média de notas, variando de **2.0** a **4.0**.\n",
        "3. **`Extracurricular_Score`**: uma pontuação que representa a participação e conquistas do estudante em atividades extracurriculares, variando de **0** a **100**.\n",
        "4. **`Community_Service_Hours`**: o total de horas que o estudante dedicou a atividades de serviço comunitário, variando de **0** a **200**.\n",
        "5. **`Financial_Need`**: indica se o estudante possui necessidade financeira.\n",
        "6. **`Scholarship_Granted`**: indica se o estudante recebeu bolsa de estudo.\n",
        "7. **`Sensitive_Attribute`**: um atributo sensível genérico com dois grupos, usado para análise de equidade (por exemplo, gênero, cor, idade, etc).\n"
      ],
      "id": "a4f1d946"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://cs.calvin.edu/courses/data/202/fsantos/datasets/student_performance.csv')\n",
        "df.loc[:,'Sensitive_Attribute'] = df['Sensitive_Attribute'].apply(lambda x: 0 if x == 'Group A' else 1)\n",
        "display(df)"
      ],
      "id": "726f40fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Treinando o modelo, considerando o atributo sensível\n"
      ],
      "id": "166d07d6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df[['GPA', 'Extracurricular_Score', 'Community_Service_Hours', 'Financial_Need', 'Sensitive_Attribute']]\n",
        "y = df['Scholarship_Granted']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)"
      ],
      "id": "7d9ac4b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Matriz de confusão {.smaller}\n",
        "\n",
        "|                           | **Classe Predita: Positiva** | **Classe Predita: Negativa** |\n",
        "| ------------------------- | ---------------------------- | ---------------------------- |\n",
        "| **Classe Real: Positiva** | Verdadeiro Positivo (VP)     | Falso Negativo (FN)          |\n",
        "| **Classe Real: Negativa** | Falso Positivo (FP)          | Verdadeiro Negativo (VN)     |\n",
        "\n",
        "---\n",
        "\n",
        "### Métricas {.smaller}\n",
        "\n",
        "| Métrica                                  | Fórmula                                             | Interpretação                                                      |\n",
        "| ---------------------------------------- | --------------------------------------------------- | ------------------------------------------------------------------ |\n",
        "| **Acurácia**                             | (VP + VN) / Total                                   | Proporção de acertos totais                                        |\n",
        "| **Precisão (Positive Predictive Value)** | VP / (VP + FP)                                      | Entre os classificados como positivos, quantos realmente são       |\n",
        "| **Revocação (Recall ou Sensibilidade)**  | VP / (VP + FN)                                      | Entre os positivos reais, quantos foram corretamente identificados |\n",
        "| **Especificidade**                       | VN / (VN + FP)                                      | Entre os negativos reais, quantos foram corretamente identificados |\n",
        "| **Taxa de Falsos Positivos (FPR)**       | FP / (FP + VN)                                      | Negativos reais classificados erroneamente como positivos          |\n",
        "| **Taxa de Falsos Negativos (FNR)**       | FN / (FN + VP)                                      | Positivos reais classificados erroneamente como negativos          |\n",
        "| **F1 Score**                             | 2 × (Precisão × Revocação) / (Precisão + Revocação) | Média harmônica entre precisão e revocação                         |\n",
        "| **Valor Preditivo Negativo (NPV)**       | VN / (VN + FN)                                      | Entre os classificados como negativos, quantos realmente são       |\n",
        "| **Taxa de Prevalência**                  | (VP + FN) / Total                                   | Proporção de positivos na população real                           |\n",
        "\n",
        "## No nosso caso:\n"
      ],
      "id": "a4f5fe11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate the confusion matrix for the entire test set\n",
        "cm_overall = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Separate the test set by the sensitive attribute\n",
        "X_test_groupA = X_test[X_test['Sensitive_Attribute'] == 0]\n",
        "y_test_groupA = y_test[X_test['Sensitive_Attribute'] == 0]\n",
        "y_pred_groupA = model.predict(X_test_groupA)\n",
        "\n",
        "X_test_groupB = X_test[X_test['Sensitive_Attribute'] == 1]\n",
        "y_test_groupB = y_test[X_test['Sensitive_Attribute'] == 1]\n",
        "y_pred_groupB = model.predict(X_test_groupB)\n",
        "\n",
        "# Calculate the confusion matrix for Group A\n",
        "cm_groupA = confusion_matrix(y_test_groupA, y_pred_groupA)\n",
        "\n",
        "# Calculate the confusion matrix for Group B\n",
        "cm_groupB = confusion_matrix(y_test_groupB, y_pred_groupB)\n",
        "\n",
        "# Create DataFrames for better readability\n",
        "cm_overall_df = pd.DataFrame(cm_overall, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
        "cm_groupA_df = pd.DataFrame(cm_groupA, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
        "cm_groupB_df = pd.DataFrame(cm_groupB, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
        "\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "display(cm_overall_df)\n",
        "print(\"\\nConfusion Matrix for Group A:\")\n",
        "display(cm_groupA_df)\n",
        "print(\"\\nConfusion Matrix for Group B:\")\n",
        "display(cm_groupB_df)"
      ],
      "id": "92cea43a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ],
      "id": "37d17d1e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "def create_metrics_table(y_true, y_pred, dataframe, group_col_name='Group'):\n",
        "    \"\"\"\n",
        "    Creates a formatted table showing various classification metrics per group.\n",
        "\n",
        "    Args:\n",
        "        y_true (pd.Series): True labels.\n",
        "        y_pred (pd.Series): Predicted labels.\n",
        "        groups (pd.Series): Series indicating the group for each data point.\n",
        "        group_col_name (str): The name to use for the group column in the output table.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the metrics per group.\n",
        "    \"\"\"\n",
        "    metrics_data = []\n",
        "    groups = dataframe.loc[y_true.index, 'Sensitive_Attribute']\n",
        "    unique_groups = groups.unique()\n",
        "\n",
        "    for group_value in unique_groups:\n",
        "        group_name = f\"{group_col_name} B\" if group_value else f\"{group_col_name} A\"\n",
        "        group_indices = groups == group_value\n",
        "\n",
        "        y_true_group = y_true[group_indices]\n",
        "        y_pred_group = y_pred[group_indices]\n",
        "\n",
        "        if len(y_true_group) == 0:\n",
        "            metrics_data.append({group_col_name: group_name,\n",
        "                                 'Acceptance Rate': np.nan,\n",
        "                                 'Accuracy': np.nan,\n",
        "                                 'Precision': np.nan,\n",
        "                                 'Recall': np.nan,\n",
        "                                 'F1-Score': np.nan})\n",
        "            continue\n",
        "\n",
        "        cm_group = confusion_matrix(y_true_group, y_pred_group)\n",
        "\n",
        "        # Calculate metrics\n",
        "        tn, fp, fn, tp = cm_group.ravel()\n",
        "        total_samples = len(y_true_group)\n",
        "\n",
        "        # Acceptance Rate (proportion of positive predictions)\n",
        "        acceptance_rate = f\"{fp + tp}/{total_samples}, {(100*(fp + tp)/total_samples):.2f}%\"\n",
        "\n",
        "        # Accuracy\n",
        "        accuracy = (tn + tp) / total_samples if total_samples > 0 else 0\n",
        "\n",
        "        # Precision (avoid division by zero if no positive predictions)\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "        # Recall (Sensitivity or True Positive Rate) (avoid division by zero if no actual positives)\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "        # F1-Score (avoid division by zero if precision and recall are zero)\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics_data.append({group_col_name: group_name,\n",
        "                             'Acceptance Rate': acceptance_rate,\n",
        "                             'Accuracy': f\"{accuracy*100:.1f}%\",\n",
        "                             'Precision': f\"{precision*100:.1f}%\",\n",
        "                             'Recall': f\"{recall*100:.1f}%\",\n",
        "                             'F1-Score': f\"{f1*100:.1f}%\"})\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "    metrics_df = metrics_df.set_index('Group')\n",
        "    metrics_df.index.name = 'Metric'\n",
        "    metrics_df = metrics_df.transpose().reindex(columns=['Group A', 'Group B'])\n",
        "    return metrics_df\n",
        "\n",
        "# Create the metrics table\n",
        "metrics_table = create_metrics_table(y_test, y_pred, df, group_col_name='Group')\n",
        "display(metrics_table)"
      ],
      "id": "d56469bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Em que momento considerar a equidade?\n",
        "\n",
        "* Pré-processamento: ajustar o espaço de atributos para que não tenha correlação com o atributo sensível.\n",
        "* Durante o treinamento: incorporar a restrição no processo de otimização que constrói o classificador.\n",
        "* Pós-processamento: ajustar um classificador já treinado para que não tenha correlação com o atributo sensível.\n",
        "\n",
        "Vamos focar no pós-processamento, considerando que o atributo sensível foi eliminado no treinamento.\n",
        "\n",
        "## Quatro estratégias\n",
        "\n",
        "Se resolvermos eliminar o atributo sensível do treinamento:\n",
        "\n",
        "1. Ignorar os grupos, usar o mesmo limiar de decisão;\n",
        "2. Usar limiares de decisão diferentes para maximizar a acurácia (\"máximo lucro\")\n",
        "3. Paridade demográfica: alcançar uma taxa de aceitação igual em todos os grupos;\n",
        "4. Paridade de erro ou acurácia: alcançar taxas iguais de verdadeiros/falsos positivos/negativos em todos os grupos.\n",
        "\n",
        "## 1a estratégia: ignorar os grupos, limiar único\n"
      ],
      "id": "8de75880"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define features (X) and target variable (y) - ignore sensitive attribute\n",
        "X = df[['GPA', 'Extracurricular_Score', 'Community_Service_Hours', 'Financial_Need']]\n",
        "y = df['Scholarship_Granted']\n",
        "\n",
        "# Convert 'Financial_Need' to numerical (0 or 1) if it's not already\n",
        "if not pd.api.types.is_numeric_dtype(X['Financial_Need']):\n",
        "    X['Financial_Need'] = X['Financial_Need'].astype(int)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)"
      ],
      "id": "1a17bdd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Problema 1: Métricas ainda continuam diferentes\n"
      ],
      "id": "6b29d858"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metrics_table = create_metrics_table(y_test, y_pred, df, group_col_name='Group')\n",
        "display(metrics_table)"
      ],
      "id": "e21e33cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def plot_probability_with_jitter_by_group(df_proba, thresholds=[0.5, 0.5], jitter_strength=0.2):\n",
        "    \"\"\"\n",
        "    Plots predicted probabilities by true class with horizontal jitter, separated by sensitive attribute group.\n",
        "\n",
        "    Parameters:\n",
        "        df_proba (pd.DataFrame): DataFrame containing 'Prob_Class_1' (predicted probabilities),\n",
        "                                 'True_Label' (actual class labels), and 'Sensitive_Attribute' (group).\n",
        "        threshold (float): Decision threshold to visualize on the plot.\n",
        "        jitter_strength (float): The maximum amount of horizontal jitter to apply to scatter points.\n",
        "\n",
        "    Returns:\n",
        "        go.Figure: The Plotly figure object with subplots.\n",
        "    \"\"\"\n",
        "    # Validate input columns\n",
        "    if 'Prob_Class_1' not in df_proba.columns or 'True_Label' not in df_proba.columns or 'Sensitive_Attribute' not in df_proba.columns:\n",
        "        raise ValueError(\"Input DataFrame must contain 'Prob_Class_1', 'True_Label', and 'Sensitive_Attribute' columns.\")\n",
        "\n",
        "    unique_groups = df_proba['Sensitive_Attribute'].unique()\n",
        "    unique_groups.sort()\n",
        "    num_groups = len(unique_groups)\n",
        "    group_names = {0: 'Group A', 1: 'Group B'}\n",
        "\n",
        "    # Create subplots: one row, multiple columns based on the number of unique groups\n",
        "    fig = make_subplots(rows=1, cols=num_groups,\n",
        "                        subplot_titles=[group_names.get(group, f'Group {group}') for group in unique_groups],\n",
        "                        horizontal_spacing=0.1) # Adjust spacing between subplots if needed\n",
        "\n",
        "    for i, group in enumerate(unique_groups):\n",
        "        col_index = i + 1 # Plotly columns are 1-indexed\n",
        "\n",
        "        df_group = df_proba[df_proba['Sensitive_Attribute'] == group].copy()\n",
        "\n",
        "        if len(df_group) == 0:\n",
        "            continue\n",
        "\n",
        "        # Add jitter to the probabilities\n",
        "        df_group['Jitter'] = np.random.uniform(-jitter_strength/2, jitter_strength/2, size=len(df_group))\n",
        "\n",
        "        # Add scatter plot for Class 0 in the group\n",
        "        fig.add_trace(go.Scattergl(\n",
        "            x=df_group[df_group['True_Label'] == 0]['Jitter'],\n",
        "            y=df_group[df_group['True_Label'] == 0]['Prob_Class_1'],\n",
        "            mode='markers',\n",
        "            name=f\"True Class 0 (Reject)\",\n",
        "            marker=dict(color=\"red\", opacity=0.5, size=6),\n",
        "            text=df_group[df_group['True_Label'] == 0].index,\n",
        "            hoverinfo='text',\n",
        "            showlegend= (i == 0) # Only show legend for the first subplot to avoid redundancy\n",
        "        ), row=1, col=col_index)\n",
        "\n",
        "        # Add scatter plot for Class 1 in the group\n",
        "        fig.add_trace(go.Scattergl(\n",
        "            x=df_group[df_group['True_Label'] == 1]['Jitter'],\n",
        "            y=df_group[df_group['True_Label'] == 1]['Prob_Class_1'],\n",
        "            mode='markers',\n",
        "            name=f\"True Class 1 (Accept)\",\n",
        "            marker=dict(color=\"blue\", opacity=0.5, size=6),\n",
        "            text=df_group[df_group['True_Label'] == 1].index,\n",
        "            hoverinfo='text',\n",
        "             showlegend= (i == 0) # Only show legend for the first subplot\n",
        "        ), row=1, col=col_index)\n",
        "\n",
        "        # Add the threshold line for each subplot\n",
        "        fig.add_hline(\n",
        "            y=thresholds[i],\n",
        "            line_dash=\"dash\",\n",
        "            line_color=\"black\",\n",
        "            annotation_text=f\"Threshold = {thresholds[i]}\",\n",
        "            annotation_position=\"top right\",\n",
        "            row=1, col=col_index\n",
        "        )\n",
        "\n",
        "        # Update layout for each subplot's axes\n",
        "        fig.update_xaxes(showticklabels=False, row=1, col=col_index) # Hide x-axis tick labels\n",
        "        fig.update_yaxes(title_text=\"Predicted Probability of Class 1\", row=1, col=col_index)\n",
        "\n",
        "    # Update global layout\n",
        "    fig.update_layout(\n",
        "        legend_title=\"True Label\",\n",
        "        height=500, # Adjust height as needed\n",
        "        width=800 # Adjust width as needed\n",
        "    )\n",
        "\n",
        "    # Return the plot\n",
        "    return fig"
      ],
      "id": "38543de4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "proba_scores = model.predict_proba(X_test)\n",
        "df_proba = pd.DataFrame(proba_scores, columns=['Prob_Class_0', 'Prob_Class_1'])\n",
        "df_proba['True_Label'] = y_test.values\n",
        "df_proba['Sensitive_Attribute'] = df.iloc[y_test.index]['Sensitive_Attribute'].values\n",
        "\n",
        "fig = plot_probability_with_jitter_by_group(df_proba)\n",
        "fig.show()"
      ],
      "id": "205e2524",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Problema 2: Discriminação por *proxy*\n",
        "\n",
        "- Outros atributos podem refletir os grupos.\n",
        "- Por exemplo, vamos identificar o atributo com maior importância:\n"
      ],
      "id": "de9187f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get feature importances from the trained model\n",
        "feature_importances = model.coef_[0]\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the feature importances\n",
        "feature_importance_df"
      ],
      "id": "a84f157a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "- Observe como o GPA é afetado pelos grupos:\n"
      ],
      "id": "3c824dd1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Group data by 'Sensitive_Attribute' and calculate the mean GPA for each group\n",
        "gpa_by_group = df.groupby('Sensitive_Attribute')['GPA'].mean()\n",
        "\n",
        "# Create a bar plot using Plotly Express\n",
        "fig = px.bar(gpa_by_group, x=gpa_by_group.index, y='GPA',\n",
        "             labels={'GPA': 'Mean GPA', 'Sensitive_Attribute': 'Group'},\n",
        "             title='Mean GPA by Sensitive Attribute')\n",
        "fig.show()"
      ],
      "id": "ffe4d5dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2a estratégia: diferentes limiares, máximo lucro\n",
        "\n",
        "Do ponto de vista de quem vai ofertar as bolsas, a ideia é acertar o máximo que puder.\n",
        "\n",
        "E se limiares diferentes forem atribuídos aos grupos de forma a maximizar os acertos?\n"
      ],
      "id": "de640e05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find the optimal threshold for Group A to minimize errors\n",
        "best_threshold_A = 0\n",
        "min_errors_A = float('inf')\n",
        "\n",
        "# Filter for groups\n",
        "df_proba_group_A = df_proba[df_proba['Sensitive_Attribute'] == 0]\n",
        "df_proba_group_B = df_proba[df_proba['Sensitive_Attribute'] == 1]\n",
        "\n",
        "for threshold in np.linspace(0, 1, 101):  # Test thresholds from 0 to 1\n",
        "    df_proba_group_A_test = df_proba_group_A.copy()\n",
        "    df_proba_group_A_test['Predicted_Label'] = (df_proba_group_A['Prob_Class_1'] >= threshold).astype(int)\n",
        "    errors_A = sum(df_proba_group_A_test['Predicted_Label'] != df_proba_group_A_test['True_Label'])\n",
        "    if errors_A < min_errors_A:\n",
        "        min_errors_A = errors_A\n",
        "        best_threshold_A = threshold\n",
        "\n",
        "print(f\"Best threshold for Group A: {best_threshold_A}\")\n",
        "print(f\"Minimum errors for Group A: {min_errors_A}\")\n",
        "\n",
        "# Find the optimal threshold for Group B to minimize errors\n",
        "best_threshold_B = 0\n",
        "min_errors_B = float('inf')\n",
        "\n",
        "for threshold in np.linspace(0, 1, 101):  # Test thresholds from 0 to 1\n",
        "    df_proba_group_B_test = df_proba_group_B.copy()\n",
        "    df_proba_group_B_test['Predicted_Label'] = (df_proba_group_B['Prob_Class_1'] >= threshold).astype(int)\n",
        "    errors_B = sum(df_proba_group_B_test['Predicted_Label'] != df_proba_group_B_test['True_Label'])\n",
        "    if errors_B < min_errors_B:\n",
        "        min_errors_B = errors_B\n",
        "        best_threshold_B = threshold\n",
        "\n",
        "print(f\"Best threshold for Group B: {best_threshold_B}\")\n",
        "print(f\"Minimum errors for Group B: {min_errors_B}\")"
      ],
      "id": "bb1128f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ],
      "id": "51fd2621"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = plot_probability_with_jitter_by_group(df_proba, thresholds=[best_threshold_A, best_threshold_B])\n",
        "fig.show()"
      ],
      "id": "02abb7f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Get y_pred based on the group-specific thresholds\n",
        "y_pred_adjusted = np.zeros_like(y_test) # Initialize with zeros (default class 0)\n",
        "\n",
        "# Apply threshold for Group A\n",
        "group_A_indices_test = df.loc[y_test.index, 'Sensitive_Attribute'] == 0\n",
        "y_pred_adjusted[group_A_indices_test] = (df_proba_group_A['Prob_Class_1'] >= best_threshold_A).astype(int)\n",
        "\n",
        "# Apply threshold for Group B\n",
        "group_B_indices_test = df.loc[y_test.index, 'Sensitive_Attribute'] == 1\n",
        "y_pred_adjusted[group_B_indices_test] = (df_proba_group_B['Prob_Class_1'] >= best_threshold_B).astype(int)\n",
        "\n",
        "metrics_table_adjusted = create_metrics_table(y_test, y_pred_adjusted, df, group_col_name='Group')\n",
        "display(metrics_table_adjusted)"
      ],
      "id": "e04c39fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3a estratégia: paridade demográfica\n",
        "\n",
        "- A mesma quantidade de pessoas de cada grupo é escolhida (Positivos A = Positivos B)\n"
      ],
      "id": "23b6ce8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find thresholds to achieve demographic parity\n",
        "def find_thresholds_for_demographic_parity(df_group_A, df_group_B, lambda_weight=0.5):\n",
        "    best_threshold_A = 0\n",
        "    best_threshold_B = 0\n",
        "    best_combined_metric = float('inf')\n",
        "\n",
        "    def calculate_accuracy(df, threshold):\n",
        "        df_test = df.copy()\n",
        "        df_test['Predicted_Label'] = (df_test['Prob_Class_1'] >= threshold).astype(int)\n",
        "        accuracy = (df_test['Predicted_Label'] == df_test['True_Label']).mean()\n",
        "        return accuracy\n",
        "\n",
        "    # Test thresholds for both groups\n",
        "    for threshold_A in np.linspace(0, 1, 101):\n",
        "        for threshold_B in np.linspace(0, 1, 101):\n",
        "            ppr_A = df_proba_group_A[df_group_A['Prob_Class_1'] >= threshold_A].shape[0]\n",
        "            ppr_B = df_proba_group_B[df_group_B['Prob_Class_1'] >= threshold_B].shape[0]\n",
        "            ppr_diff = abs(ppr_A - ppr_B)\n",
        "\n",
        "            # Calculate accuracy for both groups\n",
        "            accuracy_A = calculate_accuracy(df_group_A, threshold_A)\n",
        "            accuracy_B = calculate_accuracy(df_group_B, threshold_B)\n",
        "            overall_accuracy = (accuracy_A + accuracy_B) / 2\n",
        "\n",
        "            # Combine PPR difference and accuracy into a single metric\n",
        "            combined_metric = lambda_weight * ppr_diff - (1 - lambda_weight) * overall_accuracy\n",
        "\n",
        "            # Update best thresholds if the combined metric improves\n",
        "            if combined_metric < best_combined_metric:\n",
        "                best_combined_metric = combined_metric\n",
        "                best_threshold_A = threshold_A\n",
        "                best_threshold_B = threshold_B\n",
        "\n",
        "    return best_threshold_A, best_threshold_B\n",
        "\n",
        "# Find the thresholds for demographic parity\n",
        "best_threshold_A, best_threshold_B = find_thresholds_for_demographic_parity(df_proba_group_A, df_proba_group_B)\n",
        "\n",
        "print(f\"Threshold for Group A (Demographic Parity): {best_threshold_A}\")\n",
        "print(f\"Threshold for Group B (Demographic Parity): {best_threshold_B}\")"
      ],
      "id": "1cea8775",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ],
      "id": "af64850d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = plot_probability_with_jitter_by_group(df_proba, thresholds=[best_threshold_A, best_threshold_B])\n",
        "fig.show()"
      ],
      "id": "d26bb34f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Get y_pred based on the group-specific thresholds\n",
        "y_pred_adjusted = np.zeros_like(y_test) # Initialize with zeros (default class 0)\n",
        "\n",
        "# Apply threshold for Group A\n",
        "group_A_indices_test = df.loc[y_test.index, 'Sensitive_Attribute'] == 0\n",
        "y_pred_adjusted[group_A_indices_test] = (df_proba_group_A['Prob_Class_1'] >= best_threshold_A).astype(int)\n",
        "\n",
        "# Apply threshold for Group B\n",
        "group_B_indices_test = df.loc[y_test.index, 'Sensitive_Attribute'] == 1\n",
        "y_pred_adjusted[group_B_indices_test] = (df_proba_group_B['Prob_Class_1'] >= best_threshold_B).astype(int)\n",
        "\n",
        "metrics_table_adjusted = create_metrics_table(y_test, y_pred_adjusted, df, group_col_name='Group')\n",
        "display(metrics_table_adjusted)"
      ],
      "id": "63514691",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4a estratégia: paridade de erro ou acurácia\n",
        "\n",
        "Por exemplo, podemos tentar equalizar a taxa de verdadeiros positivos entre grupos:\n"
      ],
      "id": "5d9d87a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to calculate True Positive Rate (TPR) for a given threshold and group\n",
        "def calculate_tpr(df, threshold):\n",
        "    df_test = df.copy()\n",
        "    df_test['Predicted_Label'] = (df_test['Prob_Class_1'] >= threshold).astype(int)\n",
        "    true_positives = df_test[(df_test['Predicted_Label'] == 1) & (df_test['True_Label'] == 1)].shape[0]\n",
        "    condition_positives = df_test[df_test['True_Label'] == 1].shape[0]\n",
        "    tpr = true_positives / condition_positives if condition_positives > 0 else 0\n",
        "    return tpr\n",
        "\n",
        "def calculate_accuracy(df, threshold):\n",
        "    df_test = df.copy()\n",
        "    df_test['Predicted_Label'] = (df_test['Prob_Class_1'] >= threshold).astype(int)\n",
        "    accuracy = (df_test['Predicted_Label'] == df_test['True_Label']).mean()\n",
        "    return accuracy\n",
        "\n",
        "# Function to find thresholds for equal opportunity while balancing accuracy\n",
        "def find_thresholds_balanced_equal_opportunity(df_group_A, df_group_B, lambda_weight=0.5):\n",
        "    best_threshold_A = 0\n",
        "    best_threshold_B = 0\n",
        "    best_combined_metric = float('inf')\n",
        "\n",
        "    # Test thresholds for both groups\n",
        "    for threshold_A in np.linspace(0, 1, 101):\n",
        "        for threshold_B in np.linspace(0, 1, 101):\n",
        "            # Calculate TPR for both groups\n",
        "            tpr_A = calculate_tpr(df_group_A, threshold_A)\n",
        "            tpr_B = calculate_tpr(df_group_B, threshold_B)\n",
        "            tpr_diff = abs(tpr_A - tpr_B)\n",
        "\n",
        "            # Calculate accuracy for both groups\n",
        "            accuracy_A = calculate_accuracy(df_group_A, threshold_A)\n",
        "            accuracy_B = calculate_accuracy(df_group_B, threshold_B)\n",
        "            overall_accuracy = (accuracy_A + accuracy_B) / 2\n",
        "\n",
        "            # Combine TPR difference and accuracy into a single metric\n",
        "            combined_metric = lambda_weight * tpr_diff - (1 - lambda_weight) * overall_accuracy\n",
        "\n",
        "            # Update best thresholds if the combined metric improves\n",
        "            if combined_metric < best_combined_metric:\n",
        "                best_combined_metric = combined_metric\n",
        "                best_threshold_A = threshold_A\n",
        "                best_threshold_B = threshold_B\n",
        "\n",
        "    return best_threshold_A, best_threshold_B\n",
        "\n",
        "# Find thresholds balancing equal opportunity and accuracy\n",
        "best_threshold_A, best_threshold_B = find_thresholds_balanced_equal_opportunity(\n",
        "    df_proba_group_A, df_proba_group_B, lambda_weight=0.5\n",
        ")\n",
        "\n",
        "print(f\"Threshold for Group A (Equal Opportunity): {best_threshold_A}\")\n",
        "print(f\"Threshold for Group B (Equal Opportunity): {best_threshold_B}\")"
      ],
      "id": "ea98b8e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ],
      "id": "10511425"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig = plot_probability_with_jitter_by_group(df_proba, thresholds=[best_threshold_A, best_threshold_B])\n",
        "fig.show()"
      ],
      "id": "19e41e8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get y_pred based on the group-specific thresholds\n",
        "y_pred_adjusted = np.zeros_like(y_test) # Initialize with zeros (default class 0)\n",
        "\n",
        "# Apply threshold for Group A\n",
        "group_A_indices_test = df.loc[y_test.index, 'Sensitive_Attribute'] == 0\n",
        "y_pred_adjusted[group_A_indices_test] = (df_proba_group_A['Prob_Class_1'] >= best_threshold_A).astype(int)\n",
        "\n",
        "# Apply threshold for Group B\n",
        "group_B_indices_test = df.loc[y_test.index, 'Sensitive_Attribute'] == 1\n",
        "y_pred_adjusted[group_B_indices_test] = (df_proba_group_B['Prob_Class_1'] >= best_threshold_B).astype(int)\n",
        "\n",
        "metrics_table_adjusted = create_metrics_table(y_test, y_pred_adjusted, df, group_col_name='Group')\n",
        "display(metrics_table_adjusted)"
      ],
      "id": "1de65616",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visões sobre justiça (Barocas, Hardt, Narayanan) {.smaller}\n",
        "\n",
        "| Visão             | Objetivo                                                                                                             | Intervenção                                                    | Quem arca com o custo                                   | Exemplos de técnicas e critérios           | Problemas                                                                          |\n",
        "| ----------------- | -------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------- | ------------------------------------------ | ----------------------------------------------------------------------------------------------- |\n",
        "| **Estrita**       | Garantir que pessoas com **qualificações semelhantes** tenham **chances semelhantes** de acesso a oportunidades.     | No momento da **tomada de decisão**                            | **Ninguém**                                             | Ignorar grupos; maximizar lucro            | Ignora desigualdades históricas e estruturais; pressupõe que é possível medir o mérito.          |\n",
        "| **Intermediária** | **Desconsiderar diferenças** que surgem de **injustiças passadas**, ajustando decisões para compensar desigualdades. | Na **tomada de decisão**, especialmente em momentos críticos   | **Tomador de decisão** (pode repassar custo ao afetado) | Paridade de erro, acurácia, outros ajustes | Falta de critérios claros; risco de injustiça reversa; difícil quantificar compensações.        |\n",
        "| **Ampla**         | Garantir que pessoas com **habilidades e ambições semelhantes** possam **realizar seu potencial igualmente**.        | **Ação contínua do Estado** (educação, saúde, habitação, etc.) | **Contribuintes**                                       | Paridade demográfica; políticas públicas   | Exige mudanças estruturais; alto custo político e econômico; difícil de aplicar no curto prazo. |\n",
        "\n",
        "## Outras abordagens (talvez tentando se aproximar do meio)...\n",
        "\n",
        "---\n",
        "\n",
        "### Equidade por indivíduo\n",
        "\n",
        "- Em vez de agrupar as pessoas por categorias como gênero ou raça, avalia-se semelhança entre indivíduos com base em seus atributos relevantes (como desempenho, habilidades, contexto social)\n",
        "- Garantir que não haja discriminação entre aqueles que são equivalentes segundo esse critério.\n",
        "\n",
        "Desafios:\n",
        "\n",
        "- Como definir “semelhança”?\n",
        "- Quais atributos são relevantes para comparar indivíduos?\n",
        "- Ignorar completamente as identidades coletivas (como raça e gênero) pode, paradoxalmente, apagar as injustiças sistemáticas vividas por grupos historicamente marginalizados.\n",
        "\n",
        "---\n",
        "\n",
        "### Equidade por contrafactuais\n",
        "\n",
        "\"Se esta mesma pessoa não fosse do gênero X, ou da cor Y, ou da idade Z, o resultado seria diferente?\"\n",
        "\n",
        "Desafios:\n",
        "\n",
        "- É possível saber como seria o “mundo alternativo”?\n",
        "- Como simular a mesma pessoa com tudo igual, exceto um aspecto identitário fundamental?\n",
        "- Esbarra em limites filosóficos e técnicos da modelagem de identidades humanas...\n",
        "\n",
        "---\n",
        "\n",
        "### Equidade por causalidade\n",
        "\n",
        "Uso de modelos causais para avaliar se o atributo sensível está realmente influenciando o resultado de forma indevida.\n",
        "\n",
        "Desafios: \n",
        "\n",
        "- Conseguimos modelar corretamente todas as causas relevantes?\n",
        "- Quais variáveis ocultas não estamos considerando?\n",
        "- Bem mais sofisticado e difícil de levar adiante.\n",
        "\n",
        "---\n",
        "\n",
        "- Por exemplo, *path analysis*, *do-calculus*\n",
        "\n",
        "![](causal-ex.svg)\n",
        "\n",
        "## O problema do mérito {.smaller}\n",
        "\n",
        "> \"All Americans have not only the right, but the solemn responsibility to ascend as far as their talents and determination will take them.\" - Bill Clinton, 1995\n",
        "\n",
        "> \"Equidade significa poder competir apenas em torno daquilo que temos controle ou responsabilidade\".\n",
        "\n",
        "Parece justo, mas é extremamente **problemático**...\n",
        "\n",
        "---\n",
        "\n",
        "1. Não é simples identificar o que está e o que não está sob o controle de um indivíduo.\n",
        "    - Por exemplo, o caso de uma gravidez: a pessoa tem certo controle, mas, no geral, concordamos que isso ainda não deveria afetar seus méritos.\n",
        "\n",
        "2. Também não é simples **medir** o que está e o que não está sob o controle de um indivíduo\n",
        "\n",
        "---\n",
        "\n",
        "3. Coloca um peso infinito sobre o indivíduo\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![](sandel.jpg)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "![](future.jpg)\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "4. Faz os \"bem-sucedidos\" ignorarem a influência de fatores fora de seu controle que garantiram seus lugares.\n",
        "\n",
        "> \"Pessoas que, com um pouco de esforço e talento, vencem em uma meritocracia, carregam uma dívida pessoal que é ofuscada pela competição. [...] Dessa forma, mesmo uma meritocracia justa — em que não há trapaça, suborno ou privilégios especiais para os ricos — induz uma impressão equivocada: a de que chegamos onde estamos por conta própria. Os anos de trabalho árduo exigidos dos candidatos a universidades de elite praticamente os forçam a acreditar que seu sucesso é resultado exclusivo de suas próprias ações — e, se falharem, não têm a quem culpar senão a si mesmos. Esse é um fardo pesado para os jovens carregarem. Além disso, isso corrói as sensibilidades cívicas. Pois, quanto mais nos pensamos como pessoas autossuficientes e conquistadoras de si mesmas, mais difícil será aprender a gratidão e a humildade. E sem esses sentimentos, é difícil se importar com o bem comum.\" (Sandel, p. 23)\n",
        "\n",
        "---\n",
        "\n",
        "5. Cria uma cultura de violência\n",
        "\n",
        "- Uma cultura de esforço para \"subida social\" formenta sentimentos de **ganância e possessividade**\n",
        "    - O que gera também o pavor de ter sua própria posição/bens roubados\n",
        "    - E uma ansiedade em justificar porque uns merecem algo e outros não...\n",
        "        - Especialmente usando estatística (\"preconceito formalizado\")\n",
        "- Assim, fomenta o discurso de ódio entre grupos\n",
        "    - Justiça passa a ser \"garantir que perdedores reconheçam o lugar deles e fiquem lá\"\n",
        "    - Teorias de bode expiatório: \"o mundo está errado por causa de grupos que não estão onde deveriam estar\"\n",
        "    - Ex.: linchamentos públicos nos EUA entre 1883 e 1941\n",
        "\n",
        "## O problema da otimização\n",
        "\n",
        "* Normalmente, pessoas querem \"maximizar a utilidade/eficiência\", então acham que precisam escolher **A MELHOR** pessoa (independentemente de visões sobre justiça).\n",
        "\n",
        "  * Assim, acaba-se confiando em métodos algoritmos complexos ([veja este exemplo](https://fairmlbook.org/legitimacy.html)).\n",
        "  * No entanto, será que é sempre possível identificar **A MELHOR**?\n",
        "\n",
        "* Nessa tentativa de maximização, **os processos de tomada de decisão frequentemente acabam recorrendo a critérios e medições infundadas**.\n",
        "\n",
        "  * Divinação estatística”, apofenia...\n",
        "\n",
        "* E se **não houver uma pessoa claramente melhor**? E se todos forem suficientemente qualificados?\n",
        "\n",
        "  * **Randomização e sorteio**: um ponto defendido tanto por BHN quanto por Sandel (com as devidas e cuidadosas considerações, é claro).\n",
        "\n",
        "    * Há um argumento forte de que, **às vezes, a randomização é a melhor forma de evitar discriminação**. Reconhecer os limites do nosso conhecimento e abrir espaço para a incerteza é uma das melhores maneiras de evitar olhar para aquilo que não deveríamos considerar.\n",
        "\n",
        "\n",
        "## Uma outra perspectiva: além da escassez, da competição e do mérito\n",
        "\n",
        "Walter Brueggemann, [\"The Liturgy of Abundance, The Myth of Scarcity\"](https://www.religion-online.org/article/the-liturgy-of-abundance-the-myth-of-scarcity/)\n",
        "\n",
        "- E se o ponto de partida fosse de que há abundância no mundo e não precisamos competir em tudo?\n",
        "\n",
        "- E se a ideia de \"boa vida\" significasse mais do que o bem individual, mas também dependesse do bem de todos (bem comum)?\n",
        "\n",
        "> \"Para muitos de nós, nosso primeiro pensamento ao considerar um sistema do qual fazemos parte é: 'Como posso chegar ao topo?', em vez de: 'Como posso ajudar aqueles que estão na base?'\"\n",
        "\n",
        "\n",
        "## O princípio da solidariedade\n",
        "\n",
        "> \"A solidariedade é uma palavra que com muita frequência é esquecida ou silenciada, porque é incômoda... Ela implica criar uma nova mentalidade, que pense em termos de comunidade e da prioridade da vida de todos sobre a apropriação dos bens por parte de poucos.\"\n",
        "— Fratelli Tutti, §116, Papa Francisco\n",
        "\n",
        "Enquanto a meritocracia enfatiza a ascensão individual e o merecimento, a solidariedade enfatiza:\n",
        "\n",
        " - A natureza compartilhada da vida e das oportunidades. (\"Destino Universal dos Bens\", Compêndio, §171);\n",
        " - A responsabilidade dos fortes para com os fracos, e opção preferencial pelos pobres;\n",
        " - Que a graça, e não o mérito, é a postura fundamental.\n",
        "\n",
        "---\n",
        "\n",
        "> \"[Na perspectiva do Antigo Testamento] Os justos (ṣaddîq) estão dispostos a se colocar em desvantagem para beneficiar a comunidade; os ímpios estão dispostos a colocar a comunidade em desvantagem para beneficiar a si mesmos. Por isso, podemos dizer que a generosidade não é apenas uma questão de misericórdia, mas de justiça. Ezequiel 18:5 começa com uma afirmação geral de que o [justo], o ṣaddîq, pratica a justiça, e apresenta uma lista de onze formas concretas pelas quais os seres humanos exercem essas qualidades. Deixar de praticar qualquer uma dessas coisas é ser injusto, e a lista inclui 'partilhar o pão com o faminto e vestir o que está sem roupa' (v. 7). Portanto, não ser uma pessoa generosa é ser uma pessoa injusta.\"\n",
        "  Tim Keller, \"Justiça na Bíblia\"\n",
        "\n",
        "## Ideias? {.smaller}\n",
        "\n",
        "E se repensássemos nossos modelos não como filtros de mérito, mas como mediações de cuidado?\n",
        "\n",
        "| Pergunta tradicional (filtro de mérito) | Nova pergunta (mediação de cuidado)                          | O que isso mudaria na prática do sistema                                                           |\n",
        "| --------------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------------------------------------------------- |\n",
        "| **Quem é o melhor?**                    | **Quem está precisando de apoio?**                           | Mudança do foco de performance para vulnerabilidade; introdução de variáveis de necessidade        |\n",
        "| **Quem merece essa oportunidade?**      | **Como garantir que todos tenham acesso digno?**             | Uso de políticas de inclusão, reserva, sorteio justo quando há empate ou incerteza                 |\n",
        "| **Como evitar que o sistema erre?**     | **Como minimizar sofrimento causado por decisões injustas?** | Sistemas com canais de recurso, explicabilidade, reversibilidade; preocupação com impacto social   |\n",
        "| **Como prever com máxima precisão?**    | **Como agir com justiça mesmo quando a previsão falha?**     | Adoção de zonas de incerteza, human-in-the-loop, decisões prudenciais em vez de puramente técnicas |"
      ],
      "id": "80a31c68"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\fs33\\AppData\\Local\\anaconda3\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}