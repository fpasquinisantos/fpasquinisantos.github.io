---
title: IA na Saúde
date: 08-19-2024
author: Fernando Pasquini Santos
format:
    revealjs:
        scrollable: true
filters:
  - pyodide
---

## Aplicações atuais

- Diagnóstico por imagem
- Descoberta de medicamentos
- Ensaios clínicos e simulações
- Assistentes virtuais para pacientes

## Desafios normalmente discutidos

- Privacidade e segurança dos dados
- Viés algorítmico
- Responsabilidade e confiabilidade
- Integração com sistemas existentes
- Qualidade e disponibilidade de dados
- Interpretabilidade e explicabilidade
- Validação e regulamentação
- Impacto na formação e profissão médica

## Três iterações da IA

<style>
.small-text {
  font-size: 0.8em; /* Ajuste o valor para o tamanho de texto desejado */
}
</style>

```{mermaid}
flowchart LR
A --> B --> C;
A(<span style='font-size:40px'>Simbólica</span>)
B(<span style='font-size:40px'>Adaptativa</span>)
C(<span style='font-size:40px'>Generativa</span>)
```

- Uma necessariamente não exclui a outra. Na verdade, uma se constrói sobre a outra.

## IA Simbólica

- Termo "Inteligência Artificial" foi cunhado por John McCarthy em 1956, durante o Projeto de Pesquisa de Verão de Dartmouth sobre Inteligência Artificial.
- No entanto, estudiosos na tradição da cibernética já estavam pensando em "máquinas pensantes" e "inteligência de máquinas".
    - Por exemplo, Alan Turing publicou "Computing Machinery and Intelligence" em 1950 na revista Mind.
    - Para uma história mais ampla, veja Dupuy, J. P. (2009). On the origins of cognitive science: The mechanization of the mind. MIT Press.
- O maior sucesso foi encontrado em programas que podiam provar teoremas matemáticos, jogar xadrez e seguir regras lógicas.

## Exemplo: Xadrez

![](chess.png)

## Exemplo: fluxogramas

::: columns
::: {.column width="45%"}

![](flowchart1.jpg)
:::

::: {.column width="55%"}

```{pyodide-python}

















```
:::
:::

## Sistemas Especialistas nas décadas de 60 e 70

- Sistema de Leeds, década de 60, para diagnóstico de dor abdominal
    - Baseado em probabilidades Bayesianas
    - Acertava 91,8% dos diagnósticos, em comparação com 65-80% dos acertos pelos médicos
    - Não foi bem sucedido em outros lugares fora da cidade de Leeds, por causa de diferenças populacionais

## Sistemas Especialistas nas décadas de 60 e 70

- MYCIN, década de 70
    - baseado em regras de decisão para gerenciamento de pacientes com infecções
    - O sistema encadeia diferentes regras, determinando quais perguntas devem ser feitas. Caso não haja resposta, ele volta para trás e tenta outra regra.

## Sistemas Especialistas nas décadas de 60 e 70

- HELP, década de 70
    - Gerava alertas automáticos quando anormalidades eram detectadas no prontuário do paciente, apresentando lógicas de decisão para os profissionais.
    - Usava a sintaxe Arden, que relaciona situações e observações a ações apropriadas a tomar. Cada regra, no sistema HELP, era chamada MLM (medical logic module)

## Representação do Conhecimento

![](knowledge-representation.png)

## Bancos de dados de conhecimento de senso comum

![](common-sense.jpg)

## "O que os Computadores Não Podem Fazer", de Hubert Dreyfus

::: {.small-text}

### Conteúdo

- Introdução

**Parte I. Dez Anos de Pesquisa em Inteligência Artificial (1957-1967)**

1. Fase I (1957-1962) Simulação Cognitiva
   1. Análise do Trabalho em Tradução de Línguas, Resolução de Problemas e Reconhecimento de Padrões
   2. O Significado Subjacente do Fracasso em Alcançar Resultados Previstos

2. Fase II (1962-1967) Processamento de Informação Semântica
   1. Análise de Programas de Processamento de Informação Semântica
   2. Significado das Dificuldades Atuais

- Conclusão

**Parte II. Suposições Subjacentes ao Otimismo Persistente**

- Introdução

3. A Suposição Biológica

4. A Suposição Psicológica
   1. Evidência Empírica para a Suposição Psicológica: Crítica da Metodologia Científica da Simulação Cognitiva
   2. Argumentos A Priori para a Suposição Psicológica

5. A Suposição Epistemológica
   1. Um Argumento Errado a partir do Sucesso da Física
   2. Um Argumento Errado a partir do Sucesso da Linguística Moderna

6. A Suposição Ontológica

- Conclusão

**Parte III. Alternativas às Suposições Tradicionais**

- Introdução

7. O Papel do Corpo no Comportamento Inteligente

8. A Situação: Comportamento Ordenado sem Recurso a Regras

9. A Situação como uma Função das Necessidades Humanas

- Conclusão

**CONCLUSÃO: O Alcance e os Limites da Razão Artificial**

- Os Limites da Inteligência Artificial

- O Futuro da Inteligência Artificial

:::

---

::: {.small-text}

> "Desde que os gregos inventaram a lógica e a geometria, a ideia de que todo o raciocínio poderia ser reduzido a algum tipo de cálculo, de modo que todos os argumentos pudessem ser resolvidos de uma vez por todas, fascinou a maioria dos pensadores rigorosos da tradição ocidental. Sócrates foi o primeiro a dar voz a essa visão. A história da inteligência artificial pode muito bem começar por volta de 450 a.C., quando (segundo Platão) Sócrates exige de Eutífron, um companheiro ateniense que, em nome da piedade, está prestes a denunciar seu próprio pai por assassinato: "Eu quero saber o que é característico da piedade que faz com que todas as ações sejam piedosas... para que eu possa recorrer a isso, e usá-lo como um padrão para julgar suas ações e as de outros homens." Sócrates está pedindo a Eutífron o que os teóricos modernos de computadores chamariam de um "procedimento efetivo", "um conjunto de regras que nos diz, de momento a momento, exatamente como nos comportar."

> "A crença de que tal formalização total do conhecimento deve ser possível logo passou a dominar o pensamento ocidental. Já expressava uma demanda moral e intelectual básica, e o sucesso da ciência física parecia implicar para os filósofos do século XVI, como ainda parece sugerir para pensadores como Minsky, que a demanda poderia ser satisfeita."

:::

---

- Dreyfus recorreu à filosofia do ser-no-mundo de Heidegger para argumentar pela irredutibilidade do raciocínio humano a meras regras lógicas/formais
- Nossa corporeidade e situacionalidade humanas tornam nossa inteligência única
- Previu que algumas aplicações de IA não funcionariam, especialmente a tradução

- Ele estava certo? Em certo sentido, sim: as décadas de 70 e 80 ficaram conhecidas como o **Inverno da IA**.
    - Redução de financiamento e interesse em pesquisa de IA devido a expectativas não atendidas e promessas exageradas

## IA Adaptativa

- Em 1958, Frank Rosenblatt desenvolveu o perceptron, um tipo de rede neural artificial.
- No entanto, o potencial foi explorado apenas após uma longa experiência em sistemas especialistas
    - As pessoas começaram a notar que o perceptron era capaz de derivar regras lógicas A PARTIR DOS DADOS
- Nasce a área de **Aprendizado de Máquina** (machine learning)

## Perceptron de Rosenblatt

- A rede neural pareceria mais próxima de um modelo da cognição humana... seria ou não?

![](perceptron.png)

## Exemplo: jogue você mesmo

![https://teachablemachine.withgoogle.com/train/image](https://teachablemachine.withgoogle.com/train/image)

## Exemplo: o algoritmo da árvore de decisão

Um [artigo de 2017 da PLOS Computational Biology](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005385) sobre detecção de autismo a partir de testes de sangue.

```{python}
#| echo: false
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.io as pio
pio.templates.default = "plotly_white"
```

```{python}
#| echo: true
autism = pd.read_csv("autism.csv", skiprows=[1])
autism.info()
```

---

- Algumas manipulações e ajustes de dados
    - ASD - tem autismo
    - NEU - não tem autismo

```{python}
#| echo: true
feature_columns = list(autism.columns[1:-1])
target_column = "Group"

positive_outcome = "ASD"
negative_outcome = "NEU"

data = (
    autism
    .query("Group != 'SIB'")
    [feature_columns + [target_column]]
)
```

- Treinando um modelo de árvore de decisão

```{python}
#| echo: true
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

train, test = train_test_split(data, test_size=0.25, random_state=123)

tree = DecisionTreeClassifier(max_depth=1).fit(
    X=train[feature_columns],
    y=train[target_column]
)
```

- Plotando a árvore de decisão

```{python}
#| echo: true
from sklearn.tree import plot_tree
plot_tree(tree, feature_names=feature_columns, class_names=[negative_outcome, positive_outcome]);
```

---

- Uma árvore de decisão mais profunda

```{python}
#| echo: true
tree = DecisionTreeClassifier(max_depth=2).fit(
    X=train[feature_columns],
    y=train[target_column]
)
plot_tree(tree, feature_names=feature_columns, class_names=[negative_outcome, positive_outcome]);
```

---

- Mais fundo!!!

```{python}
#| echo: true
tree = DecisionTreeClassifier(max_depth=30).fit(
    X=train[feature_columns],
    y=train[target_column]
)
plot_tree(tree, feature_names=feature_columns, class_names=[negative_outcome, positive_outcome]);
```

## Overfitting e underfitting

- Quão generalizável é o nosso modelo?

![](overfitting.png)

## Decisões, decisões, decisões...

- De onde vieram nossos dados? Como os representamos?
- Quais são as suposições que o modelo matemático/estatístico faz sobre os dados?

- Todas essas são decisões que refletem os vieses do designer...

## Limitações dos dados

- **imprecisos** (inclusive: o que pode significar para uma pessoa pode não significar o mesmo para outra);

- **ambíguos** (podem significar várias coisas dependendo do contexto);

- **não abrangentes o suficiente** (ou o que chamamos de tendenciosos - são limitados a uma população ou situação específica e, portanto, não são generalizáveis);

- **distorcidos** (“artefatos” - não podemos ter certeza de que estão sendo transmitidos ou registrados fielmente);

- ou até **não atualizados o suficiente** (as coisas mudaram desde que os obtivemos).

---

Somos **limitados, situados e sempre vemos as coisas a partir de nossa perspectiva**. Isso não é ruim, no entanto, precisamos reconhecer essa limitação.

> “Através da confusão das línguas, através da não-comunicação, Deus impede o homem de construir [para si] uma verdade válida para todos os homens. Desta forma, a verdade do homem será sempre parcial e contestável” (Jacques Ellul, O Significado da Cidade, p. 19).

## Resumo até agora

- IA Simbólica: uma espécie de **racionalismo**
- IA Adaptativa: uma espécie de **empirismo**
    - *Ainda* com muitas suposições teóricas sobre o mundo: o fato de que poderia (ou não) representar melhor o sistema cognitivo humano não resolve o problema do **conjunto de dados de treinamento**.

- Seguindo isso, Hubert Dreyfus atualizou seu livro em uma nova edição: "O que os Computadores **Ainda** Não Podem Fazer"

---

O papel da *phronesis*, ou julgamento prático, em Aristóteles:

> “além da excelência deliberativa, parece envolver capacidades quase-perceptivas de avaliar holisticamente os fatos morais salientes de uma situação, juntamente com uma capacidade imaginativa de conceber respostas eficazes a circunstâncias sem precedentes, bem como a capacidade de integrar a compreensão do bem a ser buscado não apenas neste ato, mas em uma vida humana de maneira ampla.” ^[Vallor, S. (2017). AI and the Automation of Wisdom. In Philosophy and Computing: Essays in Epistemology, Philosophy of Mind, Logic and Ethic (pp. 161–178).]

## IA Generativa

- Trabalhos anteriores usaram modelos de Cadeias de Markov para gerar texto, mas ainda eram muito limitados.
- Mais pesquisas em redes neurais na década de 2010 levaram ao surgimento de dois modelos importantes para gerar dados: **Autoencoders Variacionais (VAE)** e **Redes Gerativas Adversárias**
    - Além disso, avanços em Processamento de Linguagem Natural também deram origem aos Transformers e Modelos de Linguagem de Grande Escala (LLMs) de hoje

## Modelos de Linguagem de Grande Escala e Transformers

![](llm.png)

## Dados de treinamento

- Centenas de GB de texto: enorme diversidade de expressão humana
    - Fatos (Wikipedia, WikiHow, discussões “como limpar manchas de molho de tomate”, etc.)
    - Conversas (fóruns de discussão, Reddit, Twitter, StackOverflow, etc.)
    - Notícias e opiniões de uma ampla gama de perspectivas
    - Ficção (fan fiction, etc.)
    - Código (GitHub, blogs de tecnologia, etc.)
    - e todo tipo de estereótipo e preconceito que você possa imaginar
- Também inclui um mecanismo de ajuste fino, incluindo feedback humano

## Generatividade versus criatividade

- Vide [Inteligência Generativa versus Inteligência Situada](https://unusmundus.academiaabc2.org.br/inteligencia-generativa-e-inteligencia-situada/)

## Desencantando a IA

- Ken Arnold: [Evite o Pensamento Mágico sobre IA](https://kenarnold.org/posts/magical-thinking/)
- Harry Collins: pense em alguns "dispositivos de desencantamento". Pense em coisas que não são reduzíveis a regras lógicas ou dados. Pense em nosso estar-no-mundo...

::: {.smaller}

> Como está, o grande perigo que enfrentamos não é a Singularidade; é não notar as deficiências dos computadores quando se trata de apreciar o contexto social e tratar todos os erros consequentes como nossa culpa. Assim, muito pior, e muito mais urgente, do que o perigo de ser escravizado por computadores enormemente inteligentes, é permitir que nos tornemos escravos de computadores estúpidos – computadores que consideramos terem resolvido os problemas difíceis, mas que, na realidade, não os resolveram de todo: o perigo não é a Singularidade, mas a Rendição! ^[Collins, Harry. Artifictional intelligence: against humanity's surrender to computers. John Wiley & Sons, 2018.]

:::

## Colocando a automação em seu lugar

- Quais são os objetivos da IA, afinal?
    - Simbólica/Adaptativa: **tomada de decisão automatizada**
    - Generativa: **produção automatizada**

    - É mais rápido, e alguns argumentariam que é "mais seguro" (?)

- No entanto, quando é bom automatizar algo? Quando não é?
    - Ou, qual é o lugar da automação em uma visão de uma vida boa e do bem comum? Qual é a ética da automação?

## Delegação e participação

- No Épico de Atrahasis, os humanos foram criados para que pudessem “assumir o trabalho penoso dos deuses.”

- No mito sumério Enki e Ninmah, eles foram criados para que os deuses “fossem liberados de seu trabalho.”

- No Enuma Elish babilônico, o deus Marduk cria o homem “sobre quem o trabalho dos deuses [seria] colocado para que eles possam descansar.”

> Esses mitos não apenas carregam a narrativa etiológica da humanidade, mas também julgam a natureza e o propósito do trabalho humano — é essencialmente apenas um fardo, e precisamos passá-lo para os menos poderosos.

## Delegação e participação

- No relato de Gênesis, Deus não está sobrecarregado por seu trabalho, mas sim se deleita nele. E a humanidade, em vez de ser criada para aliviá-lo do trabalho, foi feita para compartilhar nele. **O princípio que conecta a origem da humanidade com o propósito do trabalho não é delegação, mas participação.**

- Assim, ao delegar tudo para as máquinas (automação), podemos nos alienar da vida, do significado, do propósito.
    - Podemos nos alienar de uma espécie de "inteligência" corporificada e narrativa;
    - Podemos nos alienar da criatividade na arte e na expressão verbal.

- Em vez de nos desligarmos, a tecnologia deve nos ajudar a **engajar mais com o mundo e como ele revela a glória de Deus**. Isso não exclui a automação, mas lhe dá um propósito.
    - O papel da sabedoria na era atual é saber **quando a delegação/automação será colocada a serviço da participação**.

## Resumo: contrastes de conhecimento

- Conhecimento tácito --- conhecimento explícito
- Conhecimento narrativo --- conhecimento abstrato
- Conhecimento prudencial (*phronesis*) --- conhecimento procedural

## Proposta: auxílios ao conhecimento

- Conhecimento explícito *como suporte* ao conhecimento tácito
- Conhecimento abstrato *como suporte* ao conhecimento narrativo
- Conhecimento procedural *como suporte* ao conhecimento prudencial

- Como saber quando realmente estão sendo usados como suporte? Este é o desafio...
    - "Human-in-the-loop AI" e **além**...
    
    
